# Урок 04. "Bash, awk, sed, grep и другие"
## Домашнее задание
В результате этого ДЗ вы научитесь писать простые скрипты, решающие нужны задачи, такие как мониторинг кол-ва ошибок в логах. Освоите работу с файлами, поиском, парсингом текста, управлением блокировками.
Написать скрипт для крона
- который раз в час присылает на заданную почту:
	- X IP адресов (с наибольшим кол-вом запросов) с указанием кол-ва запросов c момента последнего запуска скрипта;
	- Y запрашиваемых адресов (с наибольшим кол-вом запросов) с указанием кол-ва запросов c момента последнего запуска скрипта;
	- все ошибки c момента последнего запуска;
	- список всех кодов возврата с указанием их кол-ва с момента последнего запуска.
- в письме должно быть прописан обрабатываемый временной диапазон
- должна быть реализована защита от мультизапуска

Критерии оценки:
- трапы и функции, а также sed и find +1 балл

## Результат

Результатом домашнего задания является скрипт `nginx_analize_log.sh`. Ниже вкратце пояснения по логике и работе скрипта.

### Параметры запуска скрипта
| Параметр       | Описание                                      |
|----------------|-----------------------------------------------|
|-e, --email     | адрес электронной почты куда отправлять отчет |
|-s, --subject   | тема письма для электронной почты             |
|-i, --iptop     | колличество адресов из ТОПа                   |
|-u, --urltop    | колличество запрашиваемых URL из ТОПа         |
|-l, --logdir    | директория с лог файлами nginx                |
|-f, --from-time | с какого времени проводить анализ логов.Задается в секундах от начала эпохи |
|--help          | вывести помощь                                |

**Пример:**
Выполнить анализ логов из директории *logs*, подсчитать ТОП5 адресов и ТОП5 URL с 01.01.1970 00:00 и отправить отчет с заголовком *"Nginx log report"* (фактически будет выполнен анализ всех логов)

```bash
# ./nginx_analize_log.sh -e admin@otus.ru -s "Nginx log report" -i 5 -u 5 -l logs -f 0
```

### Логика работы скрипта
Скрипт считывает все лог файлы с расширениями `.log` и `.log.gz` из указанной директории.

Чтобы провести анализ с заданного времени считанные файлы "прогоняются" через временный python скрипт-helper, который конвертирует дату в лог файле в число секунд с начала эпохи и добавляет первым полем в поток. Прогон через скрипт обусловлен тем, чтобы не вызывать bash'ом конвертацию в цикле и не запускать новый процесс на каждую строчку в цикле.

Следующий момент заключается в том что нам необходимо произвести подсчет нескольких величин. Для того чтобы не выполнять "прогон" по логам несколько раз, т.к. это очень накладно при большом колличестве логов используем fifo буфферы и расщепляется выходной поток при помощи комманды `tee`.

В связи с тем что утилита `sed` по идеалогическим причинам не работает с нежадными квантификаторами в регулярных выражениях, то при анализе кодов возврата используется конструкция `perl -pl`
